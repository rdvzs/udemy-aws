WEBVTT

1
00:00:00.210 --> 00:00:02.100
<v Instructor>So we have several scaling policies</v>

2
00:00:02.100 --> 00:00:03.180
for auto scaling group.

3
00:00:03.180 --> 00:00:06.360
The first one is dynamic scaling and within this category,

4
00:00:06.360 --> 00:00:08.850
we have the target tracking scaling,

5
00:00:08.850 --> 00:00:10.470
which is very simple to set up.

6
00:00:10.470 --> 00:00:13.080
The idea is that you define a metric for your ASG,

7
00:00:13.080 --> 00:00:15.390
for example, the CPU utilization

8
00:00:15.390 --> 00:00:18.720
and you define a target value, for example, 40%.

9
00:00:18.720 --> 00:00:23.720
And automatically, the ASG is going to scale out or in

10
00:00:24.150 --> 00:00:28.590
to allow you to keep this metric to around 40%.

11
00:00:28.590 --> 00:00:30.990
We also have the simple or step scaling

12
00:00:30.990 --> 00:00:33.270
and the idea is that you define CloudWatch alarms

13
00:00:33.270 --> 00:00:36.330
that are being triggered when you want to add units

14
00:00:36.330 --> 00:00:39.210
of capacity to your auto scaling group

15
00:00:39.210 --> 00:00:41.910
or when you want to remove units of capacity

16
00:00:41.910 --> 00:00:43.830
to your auto scaling group.

17
00:00:43.830 --> 00:00:45.600
Then we have scheduled scaling.

18
00:00:45.600 --> 00:00:47.910
So this is when you anticipate a scaling

19
00:00:47.910 --> 00:00:49.590
based on a known usage pattern.

20
00:00:49.590 --> 00:00:52.320
For example, you say that you know that every time

21
00:00:52.320 --> 00:00:55.920
at 5:00 PM on Fridays, you're going to get new users

22
00:00:55.920 --> 00:00:57.690
and therefore, you want to increase

23
00:00:57.690 --> 00:01:00.630
the minimum capacity to 10.

24
00:01:00.630 --> 00:01:02.880
Then we have predictive scaling.

25
00:01:02.880 --> 00:01:06.180
So this is when you continuously forecast load

26
00:01:06.180 --> 00:01:08.280
and then you start scheduling ahead of time.

27
00:01:08.280 --> 00:01:10.230
So this is very good when you have patterns

28
00:01:10.230 --> 00:01:11.250
that repeat themselves.

29
00:01:11.250 --> 00:01:13.980
So automatically, the ASG is going to analyze

30
00:01:13.980 --> 00:01:16.800
historical load then generate a forecast

31
00:01:16.800 --> 00:01:20.310
and then schedule scaling actions based on the forecast,

32
00:01:20.310 --> 00:01:24.420
which can be very handy if you have cyclical data.

33
00:01:24.420 --> 00:01:27.210
So some good metrics to scale on is a big question.

34
00:01:27.210 --> 00:01:30.450
So it depends really on what your application is doing

35
00:01:30.450 --> 00:01:31.860
and how it's working.

36
00:01:31.860 --> 00:01:34.050
But usually, here are a few.

37
00:01:34.050 --> 00:01:36.480
So number one is CPU utilization,

38
00:01:36.480 --> 00:01:39.270
because every time your instance receive a request,

39
00:01:39.270 --> 00:01:41.430
usually, they will do some sort of computation

40
00:01:41.430 --> 00:01:43.500
and so it will use some CPU.

41
00:01:43.500 --> 00:01:46.230
And so if you look at the average CPU utilization

42
00:01:46.230 --> 00:01:49.110
across all your instances and it goes higher,

43
00:01:49.110 --> 00:01:51.180
that means that your instances are being more utilized.

44
00:01:51.180 --> 00:01:53.880
And so it would be a good metric to scale on.

45
00:01:53.880 --> 00:01:57.060
Another metric to scale on, it's more application-specific,

46
00:01:57.060 --> 00:01:58.950
but it is a RequestCountPerTarget,

47
00:01:58.950 --> 00:02:00.570
which is based on your testing,

48
00:02:00.570 --> 00:02:02.970
you know that your EC2 instances operate

49
00:02:02.970 --> 00:02:06.510
at an optimal request of 1,000 requests

50
00:02:06.510 --> 00:02:09.090
per target at a time and so maybe this is the target

51
00:02:09.090 --> 00:02:11.760
you want to have for your scaling.

52
00:02:11.760 --> 00:02:12.930
So here as an example.

53
00:02:12.930 --> 00:02:15.960
You have an auto scaling group with three EC2 instances

54
00:02:15.960 --> 00:02:19.320
and your ALB is currently spreading the request

55
00:02:19.320 --> 00:02:20.430
across all of them.

56
00:02:20.430 --> 00:02:23.220
So right now the value of the request counts

57
00:02:23.220 --> 00:02:24.900
per target metric is three,

58
00:02:24.900 --> 00:02:27.600
because each EC2 instance, on average,

59
00:02:27.600 --> 00:02:30.003
has three requests outstanding.

60
00:02:30.930 --> 00:02:33.150
Next if your application is network-bound,

61
00:02:33.150 --> 00:02:35.820
so for example there's a lot of uploads and downloads

62
00:02:35.820 --> 00:02:38.430
and you know that network is going to be a bottleneck

63
00:02:38.430 --> 00:02:40.260
for your EC2 instances,

64
00:02:40.260 --> 00:02:43.350
then you may want to scale on the average network in or out

65
00:02:43.350 --> 00:02:46.470
to make sure that if you reach some certain threshold,

66
00:02:46.470 --> 00:02:48.780
then you're going to scale based on that.

67
00:02:48.780 --> 00:02:50.730
Or any custom metric that you push to CloudWatch,

68
00:02:50.730 --> 00:02:52.440
so you can set up your own metrics

69
00:02:52.440 --> 00:02:54.270
that are going to be application-specific

70
00:02:54.270 --> 00:02:57.990
and based on that, you can set up your scaling policies.

71
00:02:57.990 --> 00:03:00.240
Now one last thing you need to know about scaling policies

72
00:03:00.240 --> 00:03:02.010
is what's called a scaling cooldown.

73
00:03:02.010 --> 00:03:05.010
So the idea is that after there is a scaling activity,

74
00:03:05.010 --> 00:03:08.130
so whenever you add or you remove instances,

75
00:03:08.130 --> 00:03:10.050
you are entering the cooldown period,

76
00:03:10.050 --> 00:03:13.200
which is, by default, five minutes or 300 seconds.

77
00:03:13.200 --> 00:03:14.910
And during that cooldown period,

78
00:03:14.910 --> 00:03:19.470
the ASG will not launch or terminate additional instances.

79
00:03:19.470 --> 00:03:21.060
And the reason behind this reasoning

80
00:03:21.060 --> 00:03:24.690
is that you allow for metrics to stabilize,

81
00:03:24.690 --> 00:03:27.570
for your new instance to enter into effect

82
00:03:27.570 --> 00:03:30.240
and to see what the new metric will become.

83
00:03:30.240 --> 00:03:32.280
So the idea is that when there is a scaling action

84
00:03:32.280 --> 00:03:33.630
that occurs, the question is,

85
00:03:33.630 --> 00:03:36.090
is there a default cooldown in effect?

86
00:03:36.090 --> 00:03:37.590
If yes, then ignore the action.

87
00:03:37.590 --> 00:03:40.290
If no, then proceed with the scaling action,

88
00:03:40.290 --> 00:03:42.480
which is to launch or terminate instances.

89
00:03:42.480 --> 00:03:45.420
And so an advice to you is to use a ready-to-use AMI

90
00:03:45.420 --> 00:03:49.320
to reduce the configuration time for your EC2 instances

91
00:03:49.320 --> 00:03:52.650
in order for them to be serving the request faster.

92
00:03:52.650 --> 00:03:55.860
So if you don't spend time configuring your EC2 instance,

93
00:03:55.860 --> 00:03:58.260
then they can be in effect right away.

94
00:03:58.260 --> 00:04:00.930
And then because they can be active way faster,

95
00:04:00.930 --> 00:04:02.610
then the cooldown period can be decreased

96
00:04:02.610 --> 00:04:05.610
and you can have a more dynamic scaling up and down

97
00:04:05.610 --> 00:04:07.860
of your ASG.

98
00:04:07.860 --> 00:04:09.540
And of course, you need to make sure to enable

99
00:04:09.540 --> 00:04:11.580
something like detailed monitoring for your ASG

100
00:04:11.580 --> 00:04:15.690
to get access to metrics every one minute

101
00:04:15.690 --> 00:04:17.130
and to make sure that you have

102
00:04:17.130 --> 00:04:19.080
these metrics being updated fast enough.

103
00:04:19.080 --> 00:04:20.250
So that's it for this lecture.

104
00:04:20.250 --> 00:04:23.200
I hope you liked it and I will see you in the next lecture.

